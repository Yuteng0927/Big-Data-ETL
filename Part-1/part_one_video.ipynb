{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Activate Spark in our Colab notebook.\n",
        "import os\n",
        "# Find the latest version of spark 3.2  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.2.2'\n",
        "spark_version = 'spark-3.0.0'\n",
        "os.environ['SPARK_VERSION']=spark_version"
      ],
      "metadata": {
        "id": "1g8-gX_Mthtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# innstall java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# install spark (change the version number if needed)\n",
        "!wget -q https://apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# set your spark folder to your system path environment. \n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "# install findspark using pip\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf8zxoF2tmVT",
        "outputId": "e3158216-21d6-4d04-be7f-f67c091093fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 14.2 kB/114 kB 12%] [Connected to cloud.r\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 14.2 kB/114 kB 12%] [Connected to cloud.r\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 20.0 kB/114 kB 18%] [Waiting for headers]\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 31.5 kB/114 kB 28%] [Waiting for headers]\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "\r0% [1 InRelease 51.8 kB/114 kB 46%] [Waiting for headers] [Connecting to ppa.la\r                                                                               \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "\r0% [1 InRelease 104 kB/114 kB 91%] [Waiting for headers] [Connecting to ppa.lau\r                                                                               \r0% [Waiting for headers] [Connecting to ppa.launchpad.net (185.125.190.52)]\r                                                                           \rHit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Fetched 114 kB in 1s (76.3 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "BYmLvcp81nSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzCrgs0Z1rnw",
        "outputId": "26da4ad0-6dee-4f66-957a-ef1b3f9f3935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-19 23:32:57--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914037 (893K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.9.jar.5’\n",
            "\n",
            "postgresql-42.2.9.j 100%[===================>] 892.61K  5.70MB/s    in 0.2s    \n",
            "\n",
            "2023-02-19 23:32:57 (5.70 MB/s) - ‘postgresql-42.2.9.jar.5’ saved [914037/914037]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get postgresql package\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBfQID4muyW5",
        "outputId": "87b018b5-0bd9-4ff1-e9c3-7b49ff89d10d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pyspark 3.0.0\n",
            "Uninstalling pyspark-3.0.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/beeline\n",
            "    /usr/local/bin/beeline.cmd\n",
            "    /usr/local/bin/docker-image-tool.sh\n",
            "    /usr/local/bin/find-spark-home\n",
            "    /usr/local/bin/find-spark-home.cmd\n",
            "    /usr/local/bin/find_spark_home.py\n",
            "    /usr/local/bin/load-spark-env.cmd\n",
            "    /usr/local/bin/load-spark-env.sh\n",
            "    /usr/local/bin/pyspark\n",
            "    /usr/local/bin/pyspark.cmd\n",
            "    /usr/local/bin/pyspark2.cmd\n",
            "    /usr/local/bin/run-example\n",
            "    /usr/local/bin/run-example.cmd\n",
            "    /usr/local/bin/spark-class\n",
            "    /usr/local/bin/spark-class.cmd\n",
            "    /usr/local/bin/spark-class2.cmd\n",
            "    /usr/local/bin/spark-shell\n",
            "    /usr/local/bin/spark-shell.cmd\n",
            "    /usr/local/bin/spark-shell2.cmd\n",
            "    /usr/local/bin/spark-sql\n",
            "    /usr/local/bin/spark-sql.cmd\n",
            "    /usr/local/bin/spark-sql2.cmd\n",
            "    /usr/local/bin/spark-submit\n",
            "    /usr/local/bin/spark-submit.cmd\n",
            "    /usr/local/bin/spark-submit2.cmd\n",
            "    /usr/local/bin/sparkR\n",
            "    /usr/local/bin/sparkR.cmd\n",
            "    /usr/local/bin/sparkR2.cmd\n",
            "    /usr/local/lib/python3.8/dist-packages/pyspark-3.0.0.dist-info/*\n",
            "    /usr/local/lib/python3.8/dist-packages/pyspark/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled pyspark-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark==3.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "J-j0eLmm3Vqd",
        "outputId": "a1f1c315-8b62-40b8-8a04-43affdfbb026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.0.0\n",
            "  Using cached pyspark-3.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.8/dist-packages (from pyspark==3.0.0) (0.10.9)\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyspark"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DuBth0V2PR8"
      },
      "outputs": [],
      "source": [
        "# Import Spark and create a SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"BigData-HW-1\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3W2XJVi2CU-"
      },
      "source": [
        "# Extract the Amazon Data into Spark DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na_stw7b1wfU",
        "outputId": "b888bd78-cb84-4aac-b84d-b33f72fe2d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n",
            "|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|        review_date|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n",
            "|         US|   49033728|R1P1G5KZ05H6RD|6302503213|     748506413|The Night They Sa...|           Video|          5|            0|          0|   N|                Y|    Very satisfied!!|Fast shipping. Pl...|2015-01-31 00:08:00|\n",
            "|         US|   17857748|R106N066IUN8ZV|B000059PET|     478710180|Hamlet / Kline, N...|           Video|          5|            0|          0|   N|                Y|The most talented...|Kevin Kline is th...|2015-01-31 00:08:00|\n",
            "|         US|   25551507| R7WTAA1S5O7D9|0788812807|     981002815|Nascar Dual Power...|           Video|          4|            0|          0|   N|                Y|          Four Stars|         great movie|2015-01-31 00:08:00|\n",
            "|         US|   21025041|R32HFMVWLYOYJK|6302509939|     333219811|The Man From U.N....|           Video|          5|            0|          0|   N|                Y|          Five Stars|i love the martin...|2015-01-31 00:08:00|\n",
            "|         US|   40943563| RWT3H6HBVAL6G|B00JENS2BI|     538101194|Playboy Video Par...|           Video|          3|            0|          0|   N|                N|HOT women, dumb j...|Y'know what this ...|2015-01-31 00:08:00|\n",
            "|         US|   17013969|R1S3T3GWUGQTW7|6305761302|     716303278|Cabaret Balkan - ...|           Video|          5|            0|          0|   N|                Y|          Five Stars|Wonderfully accur...|2015-01-31 00:08:00|\n",
            "|         US|   47611685|R3R0QYHA800REE|6300157555|     134996462|Wrinkles:in Need ...|           Video|          4|            0|          0|   N|                Y|          Four Stars|In great shape fo...|2015-01-31 00:08:00|\n",
            "|         US|   35680737|R1FR0EQPHPW5NM|6300189570|     498116870|Ladies Club,the [...|           Video|          4|            1|          2|   N|                N|          Four Stars|When are they goi...|2015-01-31 00:08:00|\n",
            "|         US|   10747909| RGORN81H45NI7|B000SXQ5US|      77519275|The Campitelli Ad...|           Video|          5|            1|          1|   N|                Y|I was thrilled to...|This is the best ...|2015-01-31 00:08:00|\n",
            "|         US|     126341|R1CNYN4ABNOJSU|B00008F22G|     917778300|Return of the Jed...|           Video|          5|            0|          0|   N|                Y|          Five Stars|I'm very pleased ...|2015-01-31 00:08:00|\n",
            "|         US|   40676812|R2DW06821PMN40|6303453961|     187850980|  Class of '61 [VHS]|           Video|          3|            0|          0|   N|                Y|         Three Stars|      Poor quality--|2015-01-31 00:08:00|\n",
            "|         US|   19863533|R1CS8AMA8B0VBJ|6302453178|     901056605|Texas Carnival [VHS]|           Video|          5|            0|          0|   N|                Y|Texas Carnival movie|Great Howard Keel...|2015-01-31 00:08:00|\n",
            "|         US|   13308975|R343CPRI4MC9J0|6304475330|     472277071|National Geograph...|           Video|          5|            0|          0|   N|                N|One of my All Tim...|I loved this vide...|2015-01-31 00:08:00|\n",
            "|         US|    1989554| R3XP0G8P2BOTP|B000XPQ18W|     627738468| The Intruder Within|           Video|          5|            1|          2|   N|                Y|          Five Stars|excellent, no com...|2015-01-31 00:08:00|\n",
            "|         US|   14885930|R3NK7014K996PF|0800113055|     585148093|It Happened One N...|           Video|          2|            0|          4|   N|                Y|        Almost great|Was soon looking ...|2015-01-31 00:08:00|\n",
            "|         US|   24203443| ROIQI6ZW6UVL9|6300133338|     966466095|       Robbery [VHS]|           Video|          5|            0|          0|   N|                Y|Based on the grea...|Based on the grea...|2015-01-31 00:08:00|\n",
            "|         US|   14885930| RECPIN4UZI76Z|6304119054|     399731786|The Magnificent A...|           Video|          2|            0|          2|   N|                Y|           Not great|Honestly I didn't...|2015-01-31 00:08:00|\n",
            "|         US|   41133700|R3FE5KO613PMVI|B000006CPD|     509239068|     Streamers [VHS]|           Video|          1|            0|          0|   N|                Y|Low quality recor...|Movie is great - ...|2015-01-31 00:08:00|\n",
            "|         US|   46580399|R2EC74PS45RAOR|189218608X|     773411366|Special Kids Spee...|           Video|          5|            0|          0|   N|                Y|          Five Stars|These tapes are a...|2015-01-31 00:08:00|\n",
            "|         US|   19863533|R3FZ5C78PP7ZD7|6302754348|     536886134|Arizona Bushwhack...|           Video|          5|            1|          1|   N|                Y|Arizona Bushwacke...|Awesome Howard Ke...|2015-01-31 00:08:00|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read in the data from an S3 Bucket\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Video_v1_00.tsv.gz\"\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "df = spark.read.option('header', 'true').csv(SparkFiles.get(\"amazon_reviews_us_Video_v1_00.tsv.gz\"), inferSchema=True, sep='\\t', timestampFormat=\"yyyy-mm-dd\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cayz-3Q52IM3",
        "outputId": "1652949e-8554-4a04-f406-55926864db64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "380604"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Get the number of rows in the DataFrame.\n",
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "\n",
        "print(df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emaoa0jU6J8H",
        "outputId": "c442b9b3-acd3-4f41-ed48-a07480ae1582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "380575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9U0rkGZ2eu7"
      },
      "source": [
        "# Transform the Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print schema\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjIaFmM86j0T",
        "outputId": "64d60616-a807-4577-80bc-f829414cdb9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- marketplace: string (nullable = true)\n",
            " |-- customer_id: integer (nullable = true)\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- product_parent: integer (nullable = true)\n",
            " |-- product_title: string (nullable = true)\n",
            " |-- product_category: string (nullable = true)\n",
            " |-- star_rating: integer (nullable = true)\n",
            " |-- helpful_votes: integer (nullable = true)\n",
            " |-- total_votes: integer (nullable = true)\n",
            " |-- vine: string (nullable = true)\n",
            " |-- verified_purchase: string (nullable = true)\n",
            " |-- review_headline: string (nullable = true)\n",
            " |-- review_body: string (nullable = true)\n",
            " |-- review_date: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the \"review_id_table\"."
      ],
      "metadata": {
        "id": "dUoftWoKtM_c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tMYkSIk2d-m",
        "outputId": "50d5307e-61bd-485a-e9bd-e59fe8255ec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+----------+--------------+-------------------+\n",
            "|     review_id|customer_id|product_id|product_parent|        review_date|\n",
            "+--------------+-----------+----------+--------------+-------------------+\n",
            "|R1P1G5KZ05H6RD|   49033728|6302503213|     748506413|2015-01-31 00:08:00|\n",
            "|R106N066IUN8ZV|   17857748|B000059PET|     478710180|2015-01-31 00:08:00|\n",
            "| R7WTAA1S5O7D9|   25551507|0788812807|     981002815|2015-01-31 00:08:00|\n",
            "|R32HFMVWLYOYJK|   21025041|6302509939|     333219811|2015-01-31 00:08:00|\n",
            "| RWT3H6HBVAL6G|   40943563|B00JENS2BI|     538101194|2015-01-31 00:08:00|\n",
            "|R1S3T3GWUGQTW7|   17013969|6305761302|     716303278|2015-01-31 00:08:00|\n",
            "|R3R0QYHA800REE|   47611685|6300157555|     134996462|2015-01-31 00:08:00|\n",
            "|R1FR0EQPHPW5NM|   35680737|6300189570|     498116870|2015-01-31 00:08:00|\n",
            "| RGORN81H45NI7|   10747909|B000SXQ5US|      77519275|2015-01-31 00:08:00|\n",
            "|R1CNYN4ABNOJSU|     126341|B00008F22G|     917778300|2015-01-31 00:08:00|\n",
            "|R2DW06821PMN40|   40676812|6303453961|     187850980|2015-01-31 00:08:00|\n",
            "|R1CS8AMA8B0VBJ|   19863533|6302453178|     901056605|2015-01-31 00:08:00|\n",
            "|R343CPRI4MC9J0|   13308975|6304475330|     472277071|2015-01-31 00:08:00|\n",
            "| R3XP0G8P2BOTP|    1989554|B000XPQ18W|     627738468|2015-01-31 00:08:00|\n",
            "|R3NK7014K996PF|   14885930|0800113055|     585148093|2015-01-31 00:08:00|\n",
            "| ROIQI6ZW6UVL9|   24203443|6300133338|     966466095|2015-01-31 00:08:00|\n",
            "| RECPIN4UZI76Z|   14885930|6304119054|     399731786|2015-01-31 00:08:00|\n",
            "|R3FE5KO613PMVI|   41133700|B000006CPD|     509239068|2015-01-31 00:08:00|\n",
            "|R2EC74PS45RAOR|   46580399|189218608X|     773411366|2015-01-31 00:08:00|\n",
            "|R3FZ5C78PP7ZD7|   19863533|6302754348|     536886134|2015-01-31 00:08:00|\n",
            "+--------------+-----------+----------+--------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import to_date\n",
        "# Create the \"review_id_df\" DataFrame with the appropriate columns and data types.\n",
        "review_id_df = df.select([\"review_id\",\"customer_id\",\"product_id\", \"product_parent\",\"review_date\"])\n",
        "review_id_df.show(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the \"products\" Table"
      ],
      "metadata": {
        "id": "aAVCFjXhtXO8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9gTNhT62je4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eaf566a-2478-4d9c-c576-70a0c284a46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+\n",
            "|product_id|       product_title|\n",
            "+----------+--------------------+\n",
            "|0788806270|Bambi (Walt Disne...|\n",
            "|078881107X|Kiki's Delivery S...|\n",
            "|6303559018|To Catch a Yeti [...|\n",
            "|6302844061|      Silkwood [VHS]|\n",
            "|B00003XAMY|Wagons Roll at Ni...|\n",
            "|0783216084|          Jaws [VHS]|\n",
            "|6301966376|The Compleat Beat...|\n",
            "|6303315429| Yoga for Life [VHS]|\n",
            "|6302969204|Miracle in Milan ...|\n",
            "|6301540441|As Summers Die [VHS]|\n",
            "|6304611366|Loretta Young Sho...|\n",
            "|1559838450|Hans Christian An...|\n",
            "|6304263198|   Latcho Drom [VHS]|\n",
            "|6301017250|Dead Don't Die [VHS]|\n",
            "|6301782135|John Hammond: Fro...|\n",
            "|6304925158|The Education of ...|\n",
            "|6305403309| Dead Husbands [VHS]|\n",
            "|6300152936|       Faeries [VHS]|\n",
            "|B0000897E9|  Femme Fatale [VHS]|\n",
            "|B0002X4MIQ|Touched By An Ang...|\n",
            "+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the \"products_df\" DataFrame that drops the duplicates in the \"product_id\" and \"product_title columns. \n",
        "products_df = df.select([\"product_id\",\"product_title\"])\n",
        "products_df = products_df.dropDuplicates()\n",
        "products_df.show(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the \"customers\" Table"
      ],
      "metadata": {
        "id": "LJHuZ9zut0e5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pF2Vf3c2n2O",
        "outputId": "47de8abd-56bd-465a-d036-a850b4ded2c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+\n",
            "|customer_id|customer_count|\n",
            "+-----------+--------------+\n",
            "|   50913245|          1005|\n",
            "|   38002140|           953|\n",
            "|   18116317|           898|\n",
            "|   49778371|           765|\n",
            "|   50763106|           648|\n",
            "|   50205849|           580|\n",
            "|   49355567|           567|\n",
            "|   26803373|           559|\n",
            "|   50736950|           534|\n",
            "|    7080939|           506|\n",
            "|   49837360|           422|\n",
            "|   39371720|           394|\n",
            "|   50303974|           391|\n",
            "|   50237277|           387|\n",
            "|   51299750|           382|\n",
            "|   53016962|           380|\n",
            "|   51010646|           334|\n",
            "|   49786731|           328|\n",
            "|   49818928|           315|\n",
            "|   43921586|           310|\n",
            "+-----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the \"customers_df\" DataFrame that groups the data on the \"customer_id\" by the number of times a customer reviewed a product. \n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "customers_df = df.groupby(\"customer_id\").agg({\"customer_id\":\"count\"})\n",
        "customers_df = customers_df.orderBy(desc(\"count(customer_id)\"))\n",
        "customers_df = customers_df.withColumnRenamed(\"count(customer_id)\", \"customer_count\") \n",
        "customers_df.show(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the \"vine_table\"."
      ],
      "metadata": {
        "id": "8SbTasxbuXGK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHQKbmCE2p3Q",
        "outputId": "6a116084-5937-4b1a-b684-e6130ee85fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+-------------+-----------+----+\n",
            "|     review_id|star_rating|helpful_votes|total_votes|vine|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "|R1P1G5KZ05H6RD|          5|            0|          0|   N|\n",
            "|R106N066IUN8ZV|          5|            0|          0|   N|\n",
            "| R7WTAA1S5O7D9|          4|            0|          0|   N|\n",
            "|R32HFMVWLYOYJK|          5|            0|          0|   N|\n",
            "| RWT3H6HBVAL6G|          3|            0|          0|   N|\n",
            "|R1S3T3GWUGQTW7|          5|            0|          0|   N|\n",
            "|R3R0QYHA800REE|          4|            0|          0|   N|\n",
            "|R1FR0EQPHPW5NM|          4|            1|          2|   N|\n",
            "| RGORN81H45NI7|          5|            1|          1|   N|\n",
            "|R1CNYN4ABNOJSU|          5|            0|          0|   N|\n",
            "|R2DW06821PMN40|          3|            0|          0|   N|\n",
            "|R1CS8AMA8B0VBJ|          5|            0|          0|   N|\n",
            "|R343CPRI4MC9J0|          5|            0|          0|   N|\n",
            "| R3XP0G8P2BOTP|          5|            1|          2|   N|\n",
            "|R3NK7014K996PF|          2|            0|          4|   N|\n",
            "| ROIQI6ZW6UVL9|          5|            0|          0|   N|\n",
            "| RECPIN4UZI76Z|          2|            0|          2|   N|\n",
            "|R3FE5KO613PMVI|          1|            0|          0|   N|\n",
            "|R2EC74PS45RAOR|          5|            0|          0|   N|\n",
            "|R3FZ5C78PP7ZD7|          5|            1|          1|   N|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the \"vine_df\" DataFrame that has the \"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", and \"vine\" columns. \n",
        "# Load in a sql function to use columns\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "vine_table_df = df.select([\"review_id\",\"star_rating\",\"helpful_votes\", \"total_votes\",\"vine\"])\n",
        "\n",
        "# # Filter for only columns from Amazon's Vine program\n",
        "# vine_table_df = vine_table_df.filter(col(\"vine\")  == \"Y\")\n",
        "vine_table_df.show(20) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8aTsEjZ2s6L"
      },
      "source": [
        "# Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4dzUKfI2vXM"
      },
      "outputs": [],
      "source": [
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://<>:5432/my_data_class_db\"\n",
        "config = {\"user\":\"postgres\", \"password\": \"\", \"driver\":\"org.postgresql.Driver\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write review_id_df to table in RDS\n",
        "review_id_df.write.jdbc(url=jdbc_url, table='review_id_table', mode=mode, properties=config)"
      ],
      "metadata": {
        "id": "QusQPZ3DBOmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write products_df to table in RDS\n",
        "products_df.write.jdbc(url=jdbc_url, table='products', mode=mode, properties=config)"
      ],
      "metadata": {
        "id": "CCePCj-YBS9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write customers_df to table in RDS\n",
        "customers_df.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)"
      ],
      "metadata": {
        "id": "gVrYbdVtBV3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write vine_df to table in RDS\n",
        "vine_table_df.write.jdbc(url=jdbc_url, table='vine_table', mode=mode, properties=config)"
      ],
      "metadata": {
        "id": "7fcCqo6lBYeg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}